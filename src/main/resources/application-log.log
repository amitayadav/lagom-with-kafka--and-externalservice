15:51:17 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
15:51:17 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
15:51:17 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:41733]
15:51:17 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:41733]
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Starting up, Akka version [2.5.16] ...
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Registered cluster JMX MBean [akka:type=Cluster,port=41733]
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Started up successfully
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - No seed-nodes configured, manual cluster join required
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Node [akka.tcp://user-impl-application@127.0.0.1:41733] is JOINING itself (with roles [dc-default]) and forming new cluster
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] dc [default] is the new leader
15:51:17 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41733] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:41733] to [Up]
15:51:18 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:51:18 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
15:51:18 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:51:18 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:51:18 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:51:19 INFO  Play {play.api.Play$ start} - Application started (Dev)
15:51:19 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:51:19 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:51:19 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
15:52:06 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
15:52:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
15:52:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:43369]
15:52:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:43369]
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Starting up, Akka version [2.5.16] ...
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Registered cluster JMX MBean [akka:type=Cluster,port=43369]
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Started up successfully
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - No seed-nodes configured, manual cluster join required
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Node [akka.tcp://user-impl-application@127.0.0.1:43369] is JOINING itself (with roles [dc-default]) and forming new cluster
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] dc [default] is the new leader
15:52:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43369] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43369] to [Up]
15:52:07 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:52:07 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:52:07 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:52:07 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
15:52:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:52:08 INFO  Play {play.api.Play$ start} - Application started (Dev)
15:52:08 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:52:08 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:52:09 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
15:52:09 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:52:09 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:52:19 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
15:52:19 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:52:19 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:52:19 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:52:19 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 15715
15:52:19 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:52:20 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:52:20 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:52:20 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

15:52:20 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
15:52:20 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
15:56:47 ERROR user {com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter maybeLogException} - Exception in PathCallIdImpl(/api/consume/user)
java.lang.UnsupportedOperationException: Topic#subscribe is not permitted in the service's topic implementation.
	at com.lightbend.internal.broker.InternalTopic.subscribe(TopicProducers.scala:17)
	at com.lightbend.internal.broker.InternalTopic.subscribe$(TopicProducers.scala:16)
	at com.lightbend.internal.broker.TaggedOffsetTopicProducer.subscribe(TopicProducers.scala:20)
	at com.knoldus.impl.services.UserServiceImpl.consumeUser(UserServiceImpl.scala:37)
	at com.knoldus.impl.services.UserServiceImpl.$anonfun$checkUser$1(UserServiceImpl.scala:32)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.scaladsl.api.ServiceCall.$anonfun$handleResponseHeader$1(ServiceCall.scala:81)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:97)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:24)
	at com.lightbend.lagom.internal.server.ServiceRouter.$anonfun$handleServiceCall$1(ServiceRouter.scala:181)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$4(Accumulator.scala:174)
	at scala.util.Try$.apply(Try.scala:209)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$3(Accumulator.scala:174)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at play.api.libs.streams.StrictAccumulator.run(Accumulator.scala:207)
	at play.core.server.AkkaHttpServer.$anonfun$runAction$4(AkkaHttpServer.scala:357)
	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41)
	at akka.http.scaladsl.util.FastFuture$.$anonfun$transformWith$3(FastFuture.scala:51)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
16:10:28 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:10:28 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:10:28 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:10:28 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
16:10:28 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
16:10:29 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
16:10:29 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
16:10:29 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
16:10:29 ERROR OneForOneStrategy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$1} - com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
	at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:503)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:462)
	at akka.persistence.cassandra.package$$anon$1.$anonfun$run$1(package.scala:18)
	at scala.util.Try$.apply(Try.scala:209)
	at akka.persistence.cassandra.package$$anon$1.run(package.scala:18)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
	at com.datastax.driver.core.RequestHandler.reportNoMoreHosts(RequestHandler.java:213)
	at com.datastax.driver.core.RequestHandler.access$1000(RequestHandler.java:49)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:277)
	at com.datastax.driver.core.RequestHandler.startNewExecution(RequestHandler.java:117)
	at com.datastax.driver.core.RequestHandler.sendRequest(RequestHandler.java:97)
	at com.datastax.driver.core.SessionManager.executeAsync(SessionManager.java:132)
	at akka.persistence.cassandra.query.EventsByTagFetcher.preStart(EventsByTagFetcher.scala:86)
	at akka.actor.Actor.aroundPreStart(Actor.scala:528)
	at akka.actor.Actor.aroundPreStart$(Actor.scala:528)
	at akka.persistence.cassandra.query.EventsByTagFetcher.aroundPreStart(EventsByTagFetcher.scala:50)
	at akka.actor.ActorCell.create(ActorCell.scala:652)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	... 3 common frames omitted
16:10:29 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
16:10:29 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
16:10:29 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
18:35:11 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
18:35:11 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
18:35:11 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:40423]
18:35:11 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:40423]
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Starting up, Akka version [2.5.16] ...
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Registered cluster JMX MBean [akka:type=Cluster,port=40423]
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Started up successfully
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - No seed-nodes configured, manual cluster join required
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Node [akka.tcp://user-impl-application@127.0.0.1:40423] is JOINING itself (with roles [dc-default]) and forming new cluster
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] dc [default] is the new leader
18:35:11 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:40423] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:40423] to [Up]
18:35:12 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
18:35:12 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
18:35:12 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
18:35:12 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
18:35:12 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
18:35:13 INFO  Play {play.api.Play$ start} - Application started (Dev)
18:35:13 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
18:35:14 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
18:35:14 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
18:35:14 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
18:35:14 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
18:35:14 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
18:35:14 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
18:35:15 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
18:35:15 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
18:35:15 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 25698
18:35:15 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
18:35:15 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
18:35:15 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
18:35:15 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

18:35:15 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
18:35:15 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
18:36:00 ERROR user {com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter maybeLogException} - Exception in PathCallIdImpl(/api/consume/user)
java.lang.UnsupportedOperationException: Topic#subscribe is not permitted in the service's topic implementation.
	at com.lightbend.internal.broker.InternalTopic.subscribe(TopicProducers.scala:17)
	at com.lightbend.internal.broker.InternalTopic.subscribe$(TopicProducers.scala:16)
	at com.lightbend.internal.broker.TaggedOffsetTopicProducer.subscribe(TopicProducers.scala:20)
	at com.knoldus.impl.services.UserServiceImpl.consumeUser(UserServiceImpl.scala:39)
	at com.knoldus.impl.services.UserServiceImpl.$anonfun$checkUser$1(UserServiceImpl.scala:33)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.scaladsl.api.ServiceCall.$anonfun$handleResponseHeader$1(ServiceCall.scala:81)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:97)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:24)
	at com.lightbend.lagom.internal.server.ServiceRouter.$anonfun$handleServiceCall$1(ServiceRouter.scala:181)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$4(Accumulator.scala:174)
	at scala.util.Try$.apply(Try.scala:209)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$3(Accumulator.scala:174)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at play.api.libs.streams.StrictAccumulator.run(Accumulator.scala:207)
	at play.core.server.AkkaHttpServer.$anonfun$runAction$4(AkkaHttpServer.scala:357)
	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41)
	at akka.http.scaladsl.util.FastFuture$.$anonfun$transformWith$3(FastFuture.scala:51)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
18:44:13 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
18:44:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
18:44:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
18:44:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
18:44:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
18:44:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
18:44:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
18:44:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
18:44:14 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
18:44:14 ERROR OneForOneStrategy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$1} - com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:4000] Write attempt on defunct connection))
java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:4000] Write attempt on defunct connection))
	at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:503)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:462)
	at akka.persistence.cassandra.package$$anon$1.$anonfun$run$1(package.scala:18)
	at scala.util.Try$.apply(Try.scala:209)
	at akka.persistence.cassandra.package$$anon$1.run(package.scala:18)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:4000] Write attempt on defunct connection))
	at com.datastax.driver.core.RequestHandler.reportNoMoreHosts(RequestHandler.java:213)
	at com.datastax.driver.core.RequestHandler.access$1000(RequestHandler.java:49)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:277)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution$1.onSuccess(RequestHandler.java:317)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution$1.onSuccess(RequestHandler.java:299)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1237)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)
	at com.google.common.util.concurrent.ImmediateFuture.addListener(ImmediateFuture.java:41)
	at com.google.common.util.concurrent.Futures.addCallback(Futures.java:1209)
	at com.google.common.util.concurrent.Futures.addCallback(Futures.java:1167)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.query(RequestHandler.java:299)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:274)
	at com.datastax.driver.core.RequestHandler.startNewExecution(RequestHandler.java:117)
	at com.datastax.driver.core.RequestHandler.sendRequest(RequestHandler.java:97)
	at com.datastax.driver.core.SessionManager.executeAsync(SessionManager.java:132)
	at akka.persistence.cassandra.query.EventsByTagFetcher.preStart(EventsByTagFetcher.scala:86)
	at akka.actor.Actor.aroundPreStart(Actor.scala:528)
	at akka.actor.Actor.aroundPreStart$(Actor.scala:528)
	at akka.persistence.cassandra.query.EventsByTagFetcher.aroundPreStart(EventsByTagFetcher.scala:50)
	at akka.actor.ActorCell.create(ActorCell.scala:652)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	... 3 common frames omitted
13:05:22 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
13:05:22 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
13:05:23 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:38829]
13:05:23 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:38829]
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Starting up, Akka version [2.5.16] ...
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Registered cluster JMX MBean [akka:type=Cluster,port=38829]
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Started up successfully
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - No seed-nodes configured, manual cluster join required
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Node [akka.tcp://user-impl-application@127.0.0.1:38829] is JOINING itself (with roles [dc-default]) and forming new cluster
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] dc [default] is the new leader
13:05:23 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:38829] to [Up]
13:05:24 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:05:24 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:05:24 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
13:05:24 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:05:24 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:05:25 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:05:25 INFO  Play {play.api.Play$ start} - Application started (Dev)
13:05:25 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:05:25 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
13:05:26 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:05:26 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:05:26 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
13:05:26 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
13:05:26 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:05:26 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:05:26 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:05:27 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 1861
13:05:27 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:05:27 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:05:27 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:05:27 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

13:05:27 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
13:05:27 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
13:07:34 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:07:34 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:07:34 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:07:51 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
13:07:52 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 1 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
13:07:52 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 3 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
13:07:52 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 4 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
13:26:13 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  ClusterHeartbeatSender {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$2} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:38829] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [2586] ms ago, expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation, e.g. by running blocking tasks on the default dispatcher, CPU overload, or GC.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
13:26:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
13:26:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
13:26:14 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 INFO  LoggingRetryPolicy {com.datastax.driver.core.policies.LoggingRetryPolicy logDecision} - Retrying on request error on next host at consistency QUORUM (initial consistency: QUORUM, retries: 0, exception: {})
com.datastax.driver.core.exceptions.TransportException: [/127.0.0.1:4000] Connection has been closed
	at com.datastax.driver.core.Connection$ConnectionCloseFuture.force(Connection.java:1215)
	at com.datastax.driver.core.Connection$ConnectionCloseFuture.force(Connection.java:1200)
	at com.datastax.driver.core.Connection.defunct(Connection.java:450)
	at com.datastax.driver.core.Connection$Dispatcher.exceptionCaught(Connection.java:1133)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:87)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:87)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.exceptionCaught(DefaultChannelPipeline.java:1401)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.DefaultChannelPipeline.fireExceptionCaught(DefaultChannelPipeline.java:953)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.handleReadException(AbstractNioByteChannel.java:125)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:174)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:647)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
13:26:14 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
13:26:14 ERROR OneForOneStrategy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$1} - com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.TransportException: [/127.0.0.1:4000] Connection has been closed))
java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.TransportException: [/127.0.0.1:4000] Connection has been closed))
	at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:503)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:462)
	at akka.persistence.cassandra.package$$anon$1.$anonfun$run$1(package.scala:18)
	at scala.util.Try$.apply(Try.scala:209)
	at akka.persistence.cassandra.package$$anon$1.run(package.scala:18)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:4000 (com.datastax.driver.core.exceptions.TransportException: [/127.0.0.1:4000] Connection has been closed))
	at com.datastax.driver.core.RequestHandler.reportNoMoreHosts(RequestHandler.java:213)
	at com.datastax.driver.core.RequestHandler.access$1000(RequestHandler.java:49)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:277)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.retry(RequestHandler.java:441)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.processRetryDecision(RequestHandler.java:419)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onException(RequestHandler.java:747)
	at com.datastax.driver.core.Connection$Dispatcher.errorOutAllHandler(Connection.java:1141)
	at com.datastax.driver.core.Connection$ConnectionCloseFuture.force(Connection.java:1215)
	at com.datastax.driver.core.Connection$ConnectionCloseFuture.force(Connection.java:1200)
	at com.datastax.driver.core.Connection.defunct(Connection.java:450)
	at com.datastax.driver.core.Connection$Dispatcher.exceptionCaught(Connection.java:1133)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:87)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:87)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.exceptionCaught(DefaultChannelPipeline.java:1401)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.DefaultChannelPipeline.fireExceptionCaught(DefaultChannelPipeline.java:953)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.handleReadException(AbstractNioByteChannel.java:125)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:174)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:647)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 common frames omitted
13:26:15 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
13:26:15 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
13:26:15 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
13:26:15 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
13:27:06 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
13:27:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
13:27:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:46227]
13:27:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:46227]
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Starting up, Akka version [2.5.16] ...
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Registered cluster JMX MBean [akka:type=Cluster,port=46227]
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Started up successfully
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - No seed-nodes configured, manual cluster join required
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Node [akka.tcp://user-impl-application@127.0.0.1:46227] is JOINING itself (with roles [dc-default]) and forming new cluster
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] dc [default] is the new leader
13:27:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:46227] to [Up]
13:27:07 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:27:07 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:27:07 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
13:27:07 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:27:07 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:27:08 INFO  Play {play.api.Play$ start} - Application started (Dev)
13:27:08 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:27:08 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:27:08 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
13:27:09 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:27:09 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:27:09 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
13:27:09 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
13:27:09 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:27:10 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:27:10 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:27:10 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 4497
13:27:10 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:27:10 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:27:10 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:27:10 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

13:27:10 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
13:27:10 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
13:27:36 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:27:37 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:27:37 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:27:38 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$getUserFromExternalService$3} - new user added
13:27:50 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
13:52:48 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Marked address [akka.tcp://user-impl-application@127.0.0.1:46227] as [Leaving]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:46227]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:46227]
13:52:48 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:46227]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:46227 -> None]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:46227 -> None]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:46227 -> None]
13:52:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:52:48 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Exiting (leader), starting coordinated shutdown
13:52:48 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:46227] to [Exiting]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Exiting completed
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Shutting down...
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:46227] - Successfully shut down
13:52:49 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
13:52:49 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
13:52:49 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
13:52:49 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down.
13:52:49 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
13:52:49 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
13:52:49 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:43911]
13:52:49 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:43911]
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Starting up, Akka version [2.5.16] ...
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Registered cluster JMX MBean [akka:type=Cluster,port=43911]
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Started up successfully
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - No seed-nodes configured, manual cluster join required
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Node [akka.tcp://user-impl-application@127.0.0.1:43911] is JOINING itself (with roles [dc-default]) and forming new cluster
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] dc [default] is the new leader
13:52:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43911] to [Up]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:52:49 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:52:49 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
13:52:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:52:49 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:52:50 INFO  Play {play.api.Play$ start} - Application started (Dev)
13:52:50 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:52:50 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:52:50 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:52:50 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
13:52:50 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:52:51 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
13:52:52 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:52:52 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

13:52:52 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
13:52:52 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
13:52:52 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:52:52 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:52:53 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:52:53 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:52:53 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:57:55 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Marked address [akka.tcp://user-impl-application@127.0.0.1:43911] as [Leaving]
13:57:55 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43911]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43911]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43911]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43911 -> None]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43911 -> None]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43911 -> None]
13:57:55 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
13:57:55 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Exiting (leader), starting coordinated shutdown
13:57:55 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43911] to [Exiting]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Exiting completed
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Shutting down...
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43911] - Successfully shut down
13:57:56 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
13:57:56 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
13:57:56 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
13:57:56 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
13:57:56 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
13:57:56 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:37321]
13:57:56 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:37321]
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Starting up, Akka version [2.5.16] ...
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Registered cluster JMX MBean [akka:type=Cluster,port=37321]
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Started up successfully
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - No seed-nodes configured, manual cluster join required
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Node [akka.tcp://user-impl-application@127.0.0.1:37321] is JOINING itself (with roles [dc-default]) and forming new cluster
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] dc [default] is the new leader
13:57:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:37321] to [Up]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:57:56 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
13:57:56 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:57:56 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
13:57:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
13:57:56 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
13:57:56 INFO  Play {play.api.Play$ start} - Application started (Dev)
13:57:56 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:57:56 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:57:56 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:57:56 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
13:57:58 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
13:57:58 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

13:57:58 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:57:58 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
13:57:58 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
13:57:58 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
13:57:58 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:57:58 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
13:57:58 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
13:57:58 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
14:39:48 WARN  ClusterHeartbeatSender {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$2} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [2031] ms ago, expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation, e.g. by running blocking tasks on the default dispatcher, CPU overload, or GC.
14:39:48 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Marked address [akka.tcp://user-impl-application@127.0.0.1:37321] as [Leaving]
14:39:48 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:37321]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:37321]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:37321]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:37321 -> None]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:37321 -> None]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:37321 -> None]
14:39:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
14:39:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Exiting (leader), starting coordinated shutdown
14:39:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:37321] to [Exiting]
14:39:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
14:39:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
14:39:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
14:39:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Exiting completed
14:39:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Shutting down...
14:39:49 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:37321] - Successfully shut down
14:39:49 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
14:39:49 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
14:39:49 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
14:39:50 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
14:39:50 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
14:39:50 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:41401]
14:39:50 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:41401]
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Starting up, Akka version [2.5.16] ...
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Registered cluster JMX MBean [akka:type=Cluster,port=41401]
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Started up successfully
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - No seed-nodes configured, manual cluster join required
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Node [akka.tcp://user-impl-application@127.0.0.1:41401] is JOINING itself (with roles [dc-default]) and forming new cluster
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] dc [default] is the new leader
14:39:50 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:41401] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:41401] to [Up]
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
14:39:50 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
14:39:50 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
14:39:50 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
14:39:50 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
14:39:50 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
14:39:50 INFO  Play {play.api.Play$ start} - Application started (Dev)
14:39:50 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
14:39:50 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
14:39:50 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
14:39:51 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
14:39:52 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
14:39:52 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

14:39:52 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
14:39:52 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
14:39:52 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
14:39:52 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
14:39:52 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
14:39:52 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
14:39:52 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
14:39:52 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
14:47:55 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
14:47:55 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
14:47:55 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient processDisconnection} - Connection to node 0 could not be established. Broker may not be available.
14:47:55 ERROR OneForOneStrategy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$1} - com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
	at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:503)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:462)
	at akka.persistence.cassandra.package$$anon$1.$anonfun$run$1(package.scala:18)
	at scala.util.Try$.apply(Try.scala:209)
	at akka.persistence.cassandra.package$$anon$1.run(package.scala:18)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried)
	at com.datastax.driver.core.RequestHandler.reportNoMoreHosts(RequestHandler.java:213)
	at com.datastax.driver.core.RequestHandler.access$1000(RequestHandler.java:49)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:277)
	at com.datastax.driver.core.RequestHandler.startNewExecution(RequestHandler.java:117)
	at com.datastax.driver.core.RequestHandler.sendRequest(RequestHandler.java:97)
	at com.datastax.driver.core.SessionManager.executeAsync(SessionManager.java:132)
	at akka.persistence.cassandra.query.EventsByTagFetcher.preStart(EventsByTagFetcher.scala:86)
	at akka.actor.Actor.aroundPreStart(Actor.scala:528)
	at akka.actor.Actor.aroundPreStart$(Actor.scala:528)
	at akka.persistence.cassandra.query.EventsByTagFetcher.aroundPreStart(EventsByTagFetcher.scala:50)
	at akka.actor.ActorCell.create(ActorCell.scala:652)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	... 3 common frames omitted
14:47:56 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
14:47:56 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
14:47:56 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
14:47:58 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 4000 milliseconds
14:47:58 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 4000 milliseconds
14:47:58 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 4000 milliseconds
15:04:45 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
15:04:45 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
15:04:46 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:45267]
15:04:46 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:45267]
15:04:46 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Starting up, Akka version [2.5.16] ...
15:04:46 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Registered cluster JMX MBean [akka:type=Cluster,port=45267]
15:04:46 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Started up successfully
15:04:47 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - No seed-nodes configured, manual cluster join required
15:04:47 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Node [akka.tcp://user-impl-application@127.0.0.1:45267] is JOINING itself (with roles [dc-default]) and forming new cluster
15:04:47 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] dc [default] is the new leader
15:04:47 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:45267] to [Up]
15:04:48 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
15:04:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:04:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:04:48 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
15:04:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
15:04:48 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:04:48 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:04:49 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
15:04:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
15:04:49 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
15:04:49 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
15:04:52 INFO  Play {play.api.Play$ start} - Application started (Dev)
15:04:56 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:04:56 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
15:04:59 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:04:59 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:04:59 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
15:05:00 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
15:05:01 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:05:01 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:05:01 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:05:02 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 12255
15:05:02 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

15:05:02 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
15:05:02 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
15:05:03 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:05:03 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:05:03 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:12:18 WARN  ClusterHeartbeatSender {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$2} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [17934] ms ago, expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation, e.g. by running blocking tasks on the default dispatcher, CPU overload, or GC.
15:12:35 ERROR user {com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter maybeLogException} - Exception in PathCallIdImpl(/api/user)
akka.pattern.CircuitBreaker$$anon$1: Circuit Breaker Timed out.
15:14:25 WARN  ClusterHeartbeatSender {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$2} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [30407] ms ago, expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation, e.g. by running blocking tasks on the default dispatcher, CPU overload, or GC.
15:14:54 WARN  ClusterHeartbeatSender {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$2} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Scheduled sending of heartbeat was delayed. Previous heartbeat was sent [5080] ms ago, expected interval is [1000] ms. This may cause failure detection to mark members as unreachable. The reason can be thread starvation, e.g. by running blocking tasks on the default dispatcher, CPU overload, or GC.
15:17:05 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
15:17:06 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
15:17:06 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
15:17:19 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
15:17:20 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 4 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 5 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 6 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 7 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 8 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 9 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 10 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 11 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 12 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:21 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 13 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:22 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 14 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:22 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 15 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:22 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 16 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:22 WARN  NetworkClient {org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater handleCompletedMetadataResponse} - Error while fetching metadata with correlation id 17 : {getting-UserEvent=LEADER_NOT_AVAILABLE}
15:17:36 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$getUserFromExternalService$3} - new user added
15:17:46 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
15:22:37 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$getUserFromExternalService$3} - new user added
15:22:49 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
16:39:26 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
16:39:26 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Marked address [akka.tcp://user-impl-application@127.0.0.1:45267] as [Leaving]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:45267]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:45267]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:45267]
16:39:26 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Exiting (leader), starting coordinated shutdown
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:45267 -> None]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:45267 -> None]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:45267 -> None]
16:39:26 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:45267] to [Exiting]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:39:26 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:39:27 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:39:27 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:39:27 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:39:27 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Exiting completed
16:39:27 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Shutting down...
16:39:27 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45267] - Successfully shut down
16:39:27 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
16:39:27 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
16:39:27 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
16:39:27 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down.
16:39:29 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:39:29 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:39:29 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:36785]
16:39:29 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:36785]
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Starting up, Akka version [2.5.16] ...
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Registered cluster JMX MBean [akka:type=Cluster,port=36785]
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Started up successfully
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - No seed-nodes configured, manual cluster join required
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Node [akka.tcp://user-impl-application@127.0.0.1:36785] is JOINING itself (with roles [dc-default]) and forming new cluster
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] dc [default] is the new leader
16:39:29 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:36785] to [Up]
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:39:29 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:39:29 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:39:29 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
16:39:29 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:39:29 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:39:29 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:39:29 INFO  Play {play.api.Play$ start} - Application started (Dev)
16:39:29 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:39:29 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
16:39:29 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:39:31 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
16:39:31 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

16:39:31 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:39:31 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:39:31 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
16:39:31 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
16:39:31 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:39:31 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:39:31 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
16:39:31 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
16:40:01 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:40:01 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:40:01 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
16:40:01 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$getUserFromExternalService$3} - new user added
16:40:14 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
16:41:04 ERROR user {com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter maybeLogException} - Exception in PathCallIdImpl(/api/consume/user)
java.lang.UnsupportedOperationException: Topic#subscribe is not permitted in the service's topic implementation.
	at com.lightbend.internal.broker.InternalTopic.subscribe(TopicProducers.scala:17)
	at com.lightbend.internal.broker.InternalTopic.subscribe$(TopicProducers.scala:16)
	at com.lightbend.internal.broker.TaggedOffsetTopicProducer.subscribe(TopicProducers.scala:20)
	at com.knoldus.impl.services.UserServiceImpl.$anonfun$checkUser$1(UserServiceImpl.scala:28)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.scaladsl.api.ServiceCall.$anonfun$handleResponseHeader$1(ServiceCall.scala:81)
	at com.lightbend.lagom.scaladsl.api.ServiceCall$$anon$1.invoke(ServiceCall.scala:104)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:97)
	at com.lightbend.lagom.internal.scaladsl.server.ScaladslServiceRouter.invokeServiceCall(ScaladslServiceRouter.scala:24)
	at com.lightbend.lagom.internal.server.ServiceRouter.$anonfun$handleServiceCall$1(ServiceRouter.scala:181)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$4(Accumulator.scala:174)
	at scala.util.Try$.apply(Try.scala:209)
	at play.api.libs.streams.StrictAccumulator.$anonfun$mapFuture$3(Accumulator.scala:174)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at scala.Function1.$anonfun$andThen$1(Function1.scala:52)
	at play.api.libs.streams.StrictAccumulator.run(Accumulator.scala:207)
	at play.core.server.AkkaHttpServer.$anonfun$runAction$4(AkkaHttpServer.scala:357)
	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41)
	at akka.http.scaladsl.util.FastFuture$.$anonfun$transformWith$3(FastFuture.scala:51)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
16:41:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Marked address [akka.tcp://user-impl-application@127.0.0.1:36785] as [Leaving]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:36785]
16:41:56 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:36785]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:36785 -> None]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:36785]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:36785 -> None]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:36785 -> None]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:41:56 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:41:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Exiting (leader), starting coordinated shutdown
16:41:56 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:36785] to [Exiting]
16:41:57 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:41:57 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:41:57 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Exiting completed
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Shutting down...
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:36785] - Successfully shut down
16:41:57 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
16:41:57 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
16:41:57 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
16:41:57 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down.
16:41:57 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:41:57 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:41:57 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:34205]
16:41:57 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:34205]
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Starting up, Akka version [2.5.16] ...
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Registered cluster JMX MBean [akka:type=Cluster,port=34205]
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Started up successfully
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - No seed-nodes configured, manual cluster join required
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Node [akka.tcp://user-impl-application@127.0.0.1:34205] is JOINING itself (with roles [dc-default]) and forming new cluster
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] dc [default] is the new leader
16:41:57 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:34205] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:34205] to [Up]
16:41:57 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:41:57 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:41:57 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:41:57 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:41:57 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:41:57 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:4000 added
16:41:57 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:41:58 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:42:33 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:43:42 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:43:42 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:43:42 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:45381]
16:43:42 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:45381]
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Starting up, Akka version [2.5.16] ...
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Registered cluster JMX MBean [akka:type=Cluster,port=45381]
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Started up successfully
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - No seed-nodes configured, manual cluster join required
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Node [akka.tcp://user-impl-application@127.0.0.1:45381] is JOINING itself (with roles [dc-default]) and forming new cluster
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] dc [default] is the new leader
16:43:42 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:45381] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:45381] to [Up]
16:43:43 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
16:43:43 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:43:43 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:43:43 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:43:44 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:43:44 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:43:44 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
16:43:44 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:43:44 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:43:44 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:46:06 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:46:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:46:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:39275]
16:46:06 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:39275]
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Starting up, Akka version [2.5.16] ...
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Registered cluster JMX MBean [akka:type=Cluster,port=39275]
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Started up successfully
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - No seed-nodes configured, manual cluster join required
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Node [akka.tcp://user-impl-application@127.0.0.1:39275] is JOINING itself (with roles [dc-default]) and forming new cluster
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] dc [default] is the new leader
16:46:06 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:39275] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:39275] to [Up]
16:46:06 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:46:06 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:46:06 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:46:07 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:46:07 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:46:07 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:46:07 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:46:07 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:49:31 INFO  AkkaHttpServer {play.core.server.AkkaHttpServer stop} - Stopping server...
16:49:31 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:49:32 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
16:49:32 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
16:49:33 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 2000 milliseconds
16:49:34 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 4000 milliseconds
16:49:35 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 4000 milliseconds
16:49:38 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 8000 milliseconds
16:49:39 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 8000 milliseconds
16:51:12 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:51:12 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:51:12 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:43463]
16:51:12 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:43463]
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Starting up, Akka version [2.5.16] ...
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Registered cluster JMX MBean [akka:type=Cluster,port=43463]
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Started up successfully
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - No seed-nodes configured, manual cluster join required
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Node [akka.tcp://user-impl-application@127.0.0.1:43463] is JOINING itself (with roles [dc-default]) and forming new cluster
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] dc [default] is the new leader
16:51:12 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43463] to [Up]
16:51:13 INFO  GuavaCompatibility {com.datastax.driver.core.GuavaCompatibility selectImplementation} - Detected Guava >= 19 in the classpath, using modern compatibility layer
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:51:13 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
16:51:13 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:51:13 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:51:13 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:51:14 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:51:14 INFO  Play {play.api.Play$ start} - Application started (Dev)
16:51:15 INFO  ConsumerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = user-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = user
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaDeserializer

16:51:15 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
16:51:15 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
16:51:15 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:51:15 INFO  NettyUtil {com.datastax.driver.core.NettyUtil <clinit>} - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
16:51:15 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler onSuccess} - Discovered coordinator knoldus-Vostro-3546:9092 (id: 2147483647 rack: null) for group user.
16:51:15 INFO  ConsumerCoordinator {org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onJoinPrepare} - Revoking previously assigned partitions [] for group user
16:51:15 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator sendJoinGroupRequest} - (Re-)joining group user
16:51:15 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1 onSuccess} - Successfully joined group user with generation 1
16:51:15 INFO  ConsumerCoordinator {org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onJoinComplete} - Setting newly assigned partitions [getting-UserEvent-0] for group user
16:51:16 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:51:16 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:51:16 INFO  UserSubscriber {com.knoldus.impl.services.UserSubscriber $anonfun$new$1} - consume the user from topicUser(1,amita,female)
16:51:16 INFO  UserSubscriber {com.knoldus.impl.services.UserSubscriber $anonfun$new$1} - consume the user from topicUser(1,amita,female)
16:51:16 INFO  UserSubscriber {com.knoldus.impl.services.UserSubscriber $anonfun$new$1} - consume the user from topicUser(1,amita,female)
16:51:16 INFO  UserSubscriber {com.knoldus.impl.services.UserSubscriber $anonfun$new$1} - consume the user from topicUser(1,amita,female)
16:51:16 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:51:16 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
16:51:16 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:51:16 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:51:16 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:51:17 INFO  UUIDs {com.datastax.driver.core.utils.UUIDs getProcessPiece} - PID obtained through native call to getpid(): 16431
16:51:17 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:51:17 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

16:51:17 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
16:51:17 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
16:51:17 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:51:17 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:52:05 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:52:05 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:52:05 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:52:06 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$getUserFromExternalService$3} - new user added
16:52:19 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl convertEvent} - inside userProducer convert method
16:52:19 INFO  UserSubscriber {com.knoldus.impl.services.UserSubscriber $anonfun$new$1} - consume the user from topicUser(1,amita,female)
16:55:14 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
16:55:14 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Marked address [akka.tcp://user-impl-application@127.0.0.1:43463] as [Leaving]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43463]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43463]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Exited [akka.tcp://user-impl-application@127.0.0.1:43463]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43463 -> None]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43463 -> None]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Oldest observed OldestChanged: [akka.tcp://user-impl-application@127.0.0.1:43463 -> None]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:55:14 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Oldest -> WasOldest]
16:55:15 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Exiting (leader), starting coordinated shutdown
16:55:15 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43463] to [Exiting]
16:55:15 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:55:15 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:55:15 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [WasOldest -> Stopping]
16:55:15 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Exiting completed
16:55:15 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Shutting down...
16:55:15 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43463] - Successfully shut down
16:55:15 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Shutting down remote daemon.
16:55:15 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remote daemon shut down; proceeding with flushing remote transports.
16:55:15 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down
16:55:15 INFO  RemoteActorRefProvider$RemotingTerminator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting shut down.
16:55:16 INFO  Slf4jLogger {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 applyOrElse} - Slf4jLogger started
16:55:16 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Starting remoting
16:55:16 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting started; listening on addresses :[akka.tcp://user-impl-application@127.0.0.1:43297]
16:55:16 INFO  Remoting {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Remoting now listens on addresses: [akka.tcp://user-impl-application@127.0.0.1:43297]
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Starting up, Akka version [2.5.16] ...
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Registered cluster JMX MBean [akka:type=Cluster,port=43297]
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Started up successfully
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - No seed-nodes configured, manual cluster join required
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Node [akka.tcp://user-impl-application@127.0.0.1:43297] is JOINING itself (with roles [dc-default]) and forming new cluster
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] dc [default] is the new leader
16:55:16 INFO  Cluster(akka://user-impl-application) {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster Node [akka.tcp://user-impl-application@127.0.0.1:43297] - Leader is moving node [akka.tcp://user-impl-application@127.0.0.1:43297] to [Up]
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:55:16 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Executing cluster start task cassandraOffsetStorePrepare.
16:55:16 INFO  ClusterSingletonProxy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton identified at [akka://user-impl-application/user/cassandraOffsetStorePrepare-singleton/singleton]
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/kafkaProducer-getting-UserEventCoordinator/singleton]
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:55:16 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Singleton manager starting singleton actor [akka://user-impl-application/system/sharding/UserEntityCoordinator/singleton]
16:55:16 INFO  ClusterSingletonManager {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - ClusterSingletonManager state change [Start -> Oldest]
16:55:16 INFO  DDataShardCoordinator {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Sharding Coordinator was moved to the active state State(Map(),Map(),Set(),Set(),false)
16:55:16 INFO  Play {play.api.Play$ start} - Application started (Dev)
16:55:16 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:55:16 INFO  ConsumerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = user-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = user
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaDeserializer

16:55:16 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
16:55:16 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
16:55:16 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:55:16 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:55:16 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler onSuccess} - Discovered coordinator knoldus-Vostro-3546:9092 (id: 2147483647 rack: null) for group user.
16:55:16 INFO  ConsumerCoordinator {org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onJoinPrepare} - Revoking previously assigned partitions [] for group user
16:55:16 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator sendJoinGroupRequest} - (Re-)joining group user
16:55:16 INFO  AbstractCoordinator {org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1 onSuccess} - Successfully joined group user with generation 3
16:55:16 INFO  ConsumerCoordinator {org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onJoinComplete} - Setting newly assigned partitions [getting-UserEvent-0] for group user
16:55:16 INFO  ClusterStartupTaskActor {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$3} - Cluster start task cassandraOffsetStorePrepare done.
16:55:18 INFO  UserServiceImpl {com.knoldus.impl.services.UserServiceImpl $anonfun$userEvents$1} - inside userProducer
16:55:18 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:55:18 INFO  ProducerConfig {org.apache.kafka.common.config.AbstractConfig logAll} - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = /system/sharding/kafkaProducer-getting-UserEvent/singleton/singleton/producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.lightbend.lagom.internal.scaladsl.broker.kafka.ScaladslKafkaSerializer

16:55:18 INFO  ClockFactory {com.datastax.driver.core.ClockFactory newInstance} - Using native clock to generate timestamps.
16:55:18 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka version : 0.11.0.1
16:55:18 INFO  AppInfoParser {org.apache.kafka.common.utils.AppInfoParser$AppInfo <init>} - Kafka commitId : c2a0d5f9b1f45bf5
16:55:18 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:55:18 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
16:55:18 INFO  DCAwareRoundRobinPolicy {com.datastax.driver.core.policies.DCAwareRoundRobinPolicy init} - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
16:55:18 INFO  Cluster {com.datastax.driver.core.Cluster$Manager init} - New Cassandra host /127.0.0.1:9042 added
17:02:13 INFO  KafkaProducer {org.apache.kafka.clients.producer.KafkaProducer close} - Closing the Kafka producer with timeoutMillis = 60000 ms.
17:02:13 ERROR OneForOneStrategy {akka.event.slf4j.Slf4jLogger$$anonfun$receive$1 $anonfun$applyOrElse$1} - com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:9042] Write attempt on defunct connection))
java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:9042] Write attempt on defunct connection))
	at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:503)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:462)
	at akka.persistence.cassandra.package$$anon$1.$anonfun$run$1(package.scala:18)
	at scala.util.Try$.apply(Try.scala:209)
	at akka.persistence.cassandra.package$$anon$1.run(package.scala:18)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.ConnectionException: [/127.0.0.1:9042] Write attempt on defunct connection))
	at com.datastax.driver.core.RequestHandler.reportNoMoreHosts(RequestHandler.java:213)
	at com.datastax.driver.core.RequestHandler.access$1000(RequestHandler.java:49)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:277)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution$1.onSuccess(RequestHandler.java:317)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution$1.onSuccess(RequestHandler.java:299)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1237)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)
	at com.google.common.util.concurrent.ImmediateFuture.addListener(ImmediateFuture.java:41)
	at com.google.common.util.concurrent.Futures.addCallback(Futures.java:1209)
	at com.google.common.util.concurrent.Futures.addCallback(Futures.java:1167)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.query(RequestHandler.java:299)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.findNextHostAndQuery(RequestHandler.java:274)
	at com.datastax.driver.core.RequestHandler.startNewExecution(RequestHandler.java:117)
	at com.datastax.driver.core.RequestHandler.sendRequest(RequestHandler.java:97)
	at com.datastax.driver.core.SessionManager.executeAsync(SessionManager.java:132)
	at akka.persistence.cassandra.query.EventsByTagFetcher.preStart(EventsByTagFetcher.scala:86)
	at akka.actor.Actor.aroundPreStart(Actor.scala:528)
	at akka.actor.Actor.aroundPreStart$(Actor.scala:528)
	at akka.persistence.cassandra.query.EventsByTagFetcher.aroundPreStart(EventsByTagFetcher.scala:50)
	at akka.actor.ActorCell.create(ActorCell.scala:652)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	... 3 common frames omitted
17:02:13 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
17:02:13 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
17:02:13 ERROR ControlConnection {com.datastax.driver.core.ControlConnection$1 onConnectionException} - [Control connection] Cannot connect to any host, scheduling retry in 1000 milliseconds
